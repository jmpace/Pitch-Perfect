Complete Migration Guide: Video Processing System with Parallel Orchestration

  What You're Working On: The Big Picture

  You're working on Pitch Perfect, a video analysis application that helps entrepreneurs improve their pitch presentations. Users upload pitch videos,
   and the system automatically:

  1. Extracts video frames (thumbnails every 5 seconds for visual analysis)
  2. Transcribes speech (converts audio to text with timestamps)
  3. Analyzes the pitch (uses AI to provide coaching feedback by comparing visuals with speech)

  The challenge is that both frame extraction and transcription need to happen in parallel for good performance, but they have a dependency
  relationship that creates timing issues.

  üö® CRITICAL GUARDRAILS - READ FIRST üö®

  SCOPE LIMITATIONS - DO NOT EXCEED THESE BOUNDARIES

  ‚úÖ ALLOWED CHANGES:
  - Modify response format in /src/app/api/experiment/transcribe/route.ts (lines 78-85 only)
  - Update error handling logic in /src/app/experiment/architecture-test/page.tsx (lines 425-432 and 515-582 only)
  - Add new optional fields to ExperimentState interface
  - Update UI display for waiting states

  ‚ùå ABSOLUTELY FORBIDDEN:
  - DO NOT modify /src/app/api/experiment/extract-frames/route.ts
  - DO NOT change /src/app/api/experiment/analyze-pitch/route.ts
  - DO NOT modify the upload workflow or Vercel Blob integration
  - DO NOT change Mux configuration or API calls
  - DO NOT modify the pitch analysis functionality
  - DO NOT change database schemas or external service integrations
  - DO NOT add new API endpoints
  - DO NOT modify package.json or add new dependencies

  FUNCTIONALITY PRESERVATION REQUIREMENTS

  BEFORE making ANY changes, you MUST:

  1. Test current functionality works:
  npm run dev
  # Upload a test video
  # Verify frame extraction completes
  # Verify transcription completes 
  # Verify pitch analysis works
  2. Create a backup checkpoint:
  git add .
  git commit -m "Checkpoint before status communication migration"
  3. Test with BOTH small and large files:
    - Small video (<10MB) should work immediately
    - Large video (>25MB) should show automatic retry behavior

  ROLLBACK PLAN - MANDATORY

  If ANY functionality breaks:

  1. Immediately revert:
  git reset --hard HEAD~1
  2. Verify rollback works:
    - Test the same scenarios that failed
    - Confirm original functionality restored
  3. Do NOT proceed until you understand what broke

  TESTING REQUIREMENTS - NON-NEGOTIABLE

  After EACH change, you MUST verify:
  - Small videos still transcribe immediately
  - Large videos still show automatic retry
  - Error logs only show real errors during testing
  - UI still shows appropriate progress messages
  - No new console errors appear
  - Pitch analysis integration still works

  If ANY test fails, immediately rollback and reassess.

  The Core Problem You're Solving

  The Dependency Challenge

  What happens during video processing:
  - User uploads a video (could be 50MB, 10 minutes long)
  - Process A (Frame Extraction): Uploads video to Mux, which creates thumbnails AND a compressed audio-only file
  - Process B (Transcription): Needs that compressed audio file to send to OpenAI Whisper for speech-to-text

  The timing issue:
  - Both processes start simultaneously for performance
  - Sometimes Process B tries to start before Process A has finished creating the compressed audio
  - Process B can't proceed without the compressed audio file

  Why This Matters for the Business

  Without the compressed audio approach:
  - Large videos (>25MB) completely fail transcription due to OpenAI Whisper's file size limit
  - Users get frustrated and can't analyze their longer pitches
  - The product becomes unusable for real-world pitch videos

  With the current solution:
  - ALL videos (small and large) use the same compressed audio approach
  - Eliminates file size limits entirely
  - Provides consistent, high-quality transcription
  - But requires sophisticated coordination between parallel processes

  Current Architecture: What's Already Built

  The Elegant Parallel Processing System

  Your system currently does something quite sophisticated:

  1. Unified Audio Processing: Every video goes through Mux to create a compressed audio file (no size-based branching)
  2. Parallel Execution: Frame extraction and transcription start simultaneously
  3. Smart Coordination: When transcription can't proceed, it communicates this to the frontend
  4. Automatic Retry: When the dependency is resolved, transcription automatically retries
  5. Seamless UX: Users see continuous progress, never know about the complexity

  Why This is Better Than Alternatives

  Alternative 1 - Sequential Processing:
  - Frame extraction completes, THEN transcription starts
  - Simple code, but users wait twice as long
  - Poor user experience for longer videos

  Alternative 2 - Size-based Branching:
  - Small files go to Whisper directly, large files go through Mux
  - Complex conditional logic everywhere
  - Inconsistent audio quality between small/large files

  Your Current Approach - Unified Parallel:
  - Consistent processing for all files
  - Maximum performance through parallelism
  - Complex coordination, but elegant user experience

  The Technical Problem You're Fixing

  Current Implementation: "Fake Errors" for Coordination

  Right now, the system uses a clever but confusing approach:

  When transcription can't proceed:
  API throws: Error("Large file detected - please wait for frame extraction...")

  Frontend detects this specific error message:
  if (errorMessage.includes('Large file detected') && errorMessage.includes('wait for frame extraction')) {
    // This isn't a real error, it's coordination
    // Set up automatic retry
  }

  Why This is Problematic

  1. Confusing logs: Error logs are full of "errors" that aren't actually problems
  2. Hard to debug: Developers see errors and think something is broken
  3. Fragile: Relies on parsing specific error message text
  4. Poor developer experience: New developers are confused by fake errors
  5. Monitoring issues: Error tracking systems trigger false alarms

  üîÑ SAFE MIGRATION PLAN - FOLLOW EXACTLY

  Phase 1: Modify Transcription API Response (SAFEST CHANGE FIRST)

  File: /src/app/api/experiment/transcribe/route.ts

  üéØ EXACT LOCATION: Find lines 78-85 (the specific error throw)

  BEFORE (what you're replacing):
  if (!playbackId) {
    console.log(`‚è≥ No playbook ID available - frame extraction likely in progress`)
    throw new Error(`Large file detected - please wait for frame extraction to complete, then retry transcription. The system will automatically use 
  Mux audio-only compression.`)
  }

  AFTER (your replacement):
  if (!playbackId) {
    console.log(`‚è≥ No playbook ID available - frame extraction likely in progress`)

    return NextResponse.json({
      success: false,
      status: "waiting_for_dependency",
      message: "Audio extraction in progress",
      dependency: {
        type: "mux_playback_id",
        required_for: "audio_file_access",
        description: "Waiting for Mux to process audio-only static rendition"
      },
      estimated_wait_seconds: Math.max(30, Math.min((videoDuration || 60) * 0.5, 120)),
      retry_recommended: true,
      current_step: "audio_extraction_in_progress",
      progress_percentage: 25,
      metadata: {
        video_duration: videoDuration || 60,
        processing_started_at: new Date().toISOString(),
        transcription_method: 'mux_audio_only_whisper'
      }
    }, { status: 202 }) // 202 = Accepted, still processing
  }

  üß™ TEST IMMEDIATELY:
  - Start app: npm run dev
  - Upload a large video
  - Verify you see 202 status response instead of 500 error
  - If this breaks, rollback immediately

  Phase 2: Update Frontend Error Handling (HIGHER RISK - BE CAREFUL)

  File: /src/app/experiment/architecture-test/page.tsx

  üéØ EXACT LOCATION: Find the handleTranscription function around lines 425-432

  FIND THIS BLOCK:
  if (!whisperResponse.ok) {
    const errorData = await whisperResponse.json()
    const errorMessage = errorData.details || errorData.error || 'Whisper transcription failed'
    throw new Error(errorMessage)
  }

  REPLACE WITH:
  const whisperResult = await whisperResponse.json()

  // Handle waiting for dependency (HTTP 202 responses)
  if (whisperResponse.status === 202 || whisperResult.status === 'waiting_for_dependency') {
    console.log('‚è≥ Transcription waiting for dependency:', whisperResult.message)

    setState(prev => ({
      ...prev,
      transcriptionStage: 'waiting_for_dependency',
      transcriptionWaitingReason: whisperResult.message,
      estimatedWaitTime: whisperResult.estimated_wait_seconds,
      transcriptionProgress: whisperResult.progress_percentage || 25,
      errors: [...prev.errors, {
        section: 'transcription',
        message: `Waiting: ${whisperResult.message}`,
        timestamp: Date.now(),
        type: 'waiting' // Not an error!
      }]
    }))

    checkProcessingCompletion() // Trigger retry logic
    return // Exit function gracefully
  }

  // Handle actual errors (preserve existing error handling)
  if (!whisperResponse.ok || !whisperResult.success) {
    const errorMessage = whisperResult.error || whisperResult.details || 'Whisper transcription failed'
    throw new Error(errorMessage)
  }

  üß™ TEST IMMEDIATELY:
  - Upload large video
  - Verify waiting state displays correctly
  - Verify automatic retry still works
  - If anything breaks, rollback immediately

  Phase 3: Update ExperimentState Interface (SAFE)

  üéØ EXACT LOCATION: Find ExperimentState interface around lines 11-45

  ADD these optional fields (DO NOT remove existing fields):
  interface ExperimentState {
    // ... ALL existing fields stay exactly the same ...

    // New optional fields for explicit status communication
    transcriptionWaitingReason?: string
    estimatedWaitTime?: number
    dependencyStatus?: {
      type: string
      description: string
      estimated_resolution: number
    }
  }

  Phase 4: Update Retry Logic (HIGHEST RISK - EXTRA CAREFUL)

  üéØ EXACT LOCATION: Find checkProcessingCompletion function around lines 553-582

  FIND THIS COMPLEX RETRY LOGIC:
  const needsTranscriptionRetry = prev.extractedFrames.length > 0 &&
                                 prev.segmentedTranscript.length === 0 &&
                                 prev.errors.some(e => e.message.includes('Large file detected') && e.message.includes('wait for frame extraction'))

  REPLACE WITH SIMPLER LOGIC:
  const needsTranscriptionRetry = prev.extractedFrames.length > 0 &&
                                 prev.segmentedTranscript.length === 0 &&
                                 prev.transcriptionStage === 'waiting_for_dependency' &&
                                 prev.muxPlaybackId

  ‚ö†Ô∏è CRITICAL: Keep all other retry logic exactly the same

  Phase 5: Update UI Display (LOWEST RISK)

  ADD waiting state display (don't remove existing UI):
  {state.transcriptionStage === 'waiting_for_dependency' && (
    <div className="flex items-center space-x-2">
      <Progress value={state.transcriptionProgress || 25} className="flex-1" />
      <span className="text-sm text-blue-600">
        {state.transcriptionWaitingReason}
        {state.estimatedWaitTime && ` (~${state.estimatedWaitTime}s remaining)`}
      </span>
    </div>
  )}

  üîí SAFETY CHECKPOINTS

  After Each Phase:

  1. Immediate functional test:
    - Upload small video ‚Üí should work immediately
    - Upload large video ‚Üí should show waiting then succeed
    - Check browser console for new errors
  2. Commit progress:
  git add .
  git commit -m "Phase [X] completed - [description]"
  3. If anything fails:
  git reset --hard HEAD~1
  npm run dev
  # Test again

  Final Validation Checklist:

  - Small videos: Immediate transcription (no waiting)
  - Large videos: Shows "waiting" message then succeeds
  - Error logs: Only real errors, no fake coordination errors
  - UI: Smooth progress, no error flashes during normal flow
  - Pitch analysis: Still works end-to-end
  - No new console errors or warnings

  üö® RED FLAGS - STOP IMMEDIATELY IF YOU SEE:

  - Any video fails to transcribe that worked before
  - Automatic retry stops working
  - Users see error messages during normal flow
  - Pitch analysis breaks
  - New console errors appear
  - App becomes unresponsive

  If you see any red flags: Rollback immediately and reassess.

  Success Criteria

  Must Work Exactly the Same:

  - Small videos transcribe immediately (no waiting)
  - Large videos show progress and automatically retry
  - Users never see errors during normal coordination
  - Final results are identical

  Must Improve:

  - Error logs only contain real errors
  - Code is easier to understand
  - Debugging is straightforward

  Must Not Break:

  - Existing user workflows
  - Performance characteristics
  - Error handling for real problems
  - Integration with pitch analysis

  This migration is about improving developer experience while preserving user experience. The guardrails ensure you can't accidentally break the
  sophisticated coordination system that users depend on.